@inproceedings{michael2015,
  author = {R\"{o}der, Michael and Both, Andreas and Hinneburg, Alexander},
  title = {Exploring the Space of Topic Coherence Measures},
  year = {2015},
  isbn = {9781450333177},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/2684822.2685324},
  doi = {10.1145/2684822.2685324},
  booktitle = {Proceedings of the Eighth ACM International Conference on Web Search and Data Mining},
  pages = {399–408},
  numpages = {10},
  series = {WSDM '15}
}

@inproceedings{LDAvis,
  author = {Sievert, Carson and Shirley, Kenneth},
  year = {2014},
  month = {06},
  pages = {},
  title = {LDAvis: A method for visualizing and interpreting topics},
  doi = {10.13140/2.1.1394.3043}
}

@article{LDA,
  author = {Blei, David M. and Ng, Andrew Y. and Jordan, Michael I.},
  title = {Latent Dirichlet Allocation},
  year = {2003},
  issue_date = {3/1/2003},
  publisher = {JMLR.org},
  volume = {3},
  number = {null},
  issn = {1532-4435},
  journal = {J. Mach. Learn. Res.},
  month = mar,
  pages = {993–1022},
  numpages = {30}
}

@inproceedings{gibbs_lda,
  author = {Qiu, Zhuolin and Wu, Bin and Wang, Bai and Shi, Chuan and Yu, Le},
  title = {Collapsed Gibbs Sampling for Latent Dirichlet Allocation on Spark},
  year = {2014},
  publisher = {JMLR.org},
  booktitle = {Proceedings of the 3rd International Conference on Big Data, Streams and Heterogeneous Source Mining: Algorithms, Systems, Programming Models and Applications - Volume 36},
  pages = {17–28},
  numpages = {12},
  keywords = {LDA, spark, collapsed gibbs sampling},
  location = {New York, NY},
  series = {BIGMINE'14}
}

@article{rbcbaestmro32000a,
  author = {Hintzen, Rogier E. and Papadopoulou, Marina and Mounce, Ross and Banks-Leite, Cristina and Holt, Robert D. and Mills, Morena and T. Knight, Andrew and Leroi, Armand M. and Rosindell, James},
  title = {Relationship between conservation biology and ecology shown through machine reading of 32,000 articles},
  journal = {Conservation Biology},
  volume = {34},
  number = {3},
  pages = {721-732},
  keywords = {bibliometrics, ecological applications, ecological theory, interdisciplinary, latent Dirichlet allocation, aplicaciones ecológicas, asignación latente Dirichlet, bibliometría, interdisciplinario, teoría ecológica, 潜在狄利克雷分布模型, 跨学科, 生态学理论, 生态学应用, 文献计量学},
  doi = {https://doi.org/10.1111/cobi.13435},
  url = {https://conbio.onlinelibrary.wiley.com/doi/abs/10.1111/cobi.13435},
  eprint = {https://conbio.onlinelibrary.wiley.com/doi/pdf/10.1111/cobi.13435},
  abstract = {Abstract Conservation biology was founded on the idea that efforts to save nature depend on a scientific understanding of how it works. It sought to apply ecological principles to conservation problems. We investigated whether the relationship between these fields has changed over time through machine reading the full texts of 32,000 research articles published in 16 ecology and conservation biology journals. We examined changes in research topics in both fields and how the fields have evolved from 2000 to 2014. As conservation biology matured, its focus shifted from ecology to social and political aspects of conservation. The 2 fields diverged and now occupy distinct niches in modern science. We hypothesize this pattern resulted from increasing recognition that social, economic, and political factors are critical for successful conservation and possibly from rising skepticism about the relevance of contemporary ecological theory to practical conservation.},
  year = {2020}
}

@article{sseutm,
  title={Studying software evolution using topic models},
  author={S. W. Thomas and B. Adams and A. Hassan and D. Blostein},
  journal={Sci. Comput. Program.},
  year={2014},
  volume={80},
  pages={457-479}
}

@inproceedings{daitmbapv,
  title={Diagnosing and Improving Topic Models by Analyzing Posterior Variability},
  author={Linzi Xing and Michael J. Paul},
  booktitle={AAAI},
  year={2018}
}

@inproceedings{chuang2015,
    title = "{T}opic{C}heck: Interactive Alignment for Assessing Topic Model Stability",
    author = "Chuang, Jason  and
      Roberts, Margaret E.  and
      Stewart, Brandon M.  and
      Weiss, Rebecca  and
      Tingley, Dustin  and
      Grimmer, Justin  and
      Heer, Jeffrey",
    booktitle = "Proceedings of the 2015 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies",
    month = may # "{--}" # jun,
    year = "2015",
    address = "Denver, Colorado",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/N15-1018",
    doi = "10.3115/v1/N15-1018",
    pages = "175--184",
}

@inproceedings{Wang2019,
  title={Evaluating Similarity Metrics for Latent Twitter Topics},
  author={Xi Wang and Anjie Fang and I. Ounis and C. MacDonald},
  booktitle={ECIR},
  year={2019}
}

@inproceedings{Kim2011,
  author = {Kim, Dongwoo and Oh, Alice},
  year = {2011},
  month = {02},
  pages = {163-176},
  title = {Topic Chains for Understanding a News Corpus},
  isbn = {978-3-642-19436-8},
  doi = {10.1007/978-3-642-19437-5_13}
}

@article{hungarian,
  author = {Kuhn, H. W.},
  title = {The Hungarian method for the assignment problem},
  journal = {Naval Research Logistics Quarterly},
  volume = {2},
  number = {1-2},
  pages = {83-97},
  doi = {https://doi.org/10.1002/nav.3800020109},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/nav.3800020109},
  eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/nav.3800020109},
  year = {1955}
}

@article{ward,
  author = { Joe H.   Ward   Jr. },
  title = {Hierarchical Grouping to Optimize an Objective Function},
  journal = {Journal of the American Statistical Association},
  volume = {58},
  number = {301},
  pages = {236-244},
  year  = {1963},
  publisher = {Taylor & Francis},
  doi = {10.1080/01621459.1963.10500845},

  URL = {
          https://www.tandfonline.com/doi/abs/10.1080/01621459.1963.10500845

  },
  eprint = {
          https://www.tandfonline.com/doi/pdf/10.1080/01621459.1963.10500845

  }

}

@INPROCEEDINGS{ward2,
  author={Miyamoto, Sadaaki and Abe, Ryosuke and Endo, Yasunori and Takeshita, Jun-ichi},
  booktitle={2015 7th International Conference of Soft Computing and Pattern Recognition (SoCPaR)},
  title={Ward method of hierarchical clustering for non-Euclidean similarity measures},
  year={2015},
  volume={},
  number={},
  pages={60-63},
  doi={10.1109/SOCPAR.2015.7492784}}

@article{Magua2017,
  author = {Magua, Wairimu and Zhu, Xiaojin and Bhattacharya, Anupama and Filut, Amarette and Potvien, Aaron and Leatherberry, Renee and Lee, You-Geon and Jens, Madeline and Malikireddy, Dastagiri and Carnes, Molly and Kaatz, Anna},
  year = {2017},
  month = {03},
  pages = {},
  title = {Are Female Applicants Disadvantaged in National Institutes of Health Peer Review? Combining Algorithmic Text Mining and Qualitative Methods to Detect Evaluative Differences in R01 Reviewers' Critiques},
  volume = {26},
  journal = {Journal of Women's Health},
  doi = {10.1089/jwh.2016.6021}
}

@article{Acuna2012,
  author = {Acuna, Daniel and Allesina, Stefano and Kording, Konrad},
  year = {2012},
  month = {09},
  pages = {201-2},
  title = {Future impact: Predicting scientific success},
  volume = {489},
  journal = {Nature},
  doi = {10.1038/489201a}
}

@article{allesina2011,
  doi = {10.1371/journal.pone.0021160},
  author = {Allesina, Stefano},
  journal = {PLOS ONE},
  publisher = {Public Library of Science},
  title = {Measuring Nepotism through Shared Last Names: The Case of Italian Academia},
  year = {2011},
  month = {08},
  volume = {6},
  url = {https://doi.org/10.1371/journal.pone.0021160},
  pages = {1-6},
  number = {8}
}

@article{sarigol2014,
  author = {Sarigöl, Emre and Pfitzner, Rene and Scholtes, Ingo and Garas, Antonios and Schweitzer, Frank},
  year = {2014},
  month = {02},
  pages = {},
  title = {Predicting Scientific Success Based on Coauthorship Networks},
  journal = {EPJ Data Science},
  doi = {10.1140/epjds/s13688-014-0009-x}
}

@article{david2014,
  title = {Publication metrics and success on the academic job market},
  journal = {Current Biology},
  volume = {24},
  number = {11},
  pages = {R516-R517},
  year = {2014},
  issn = {0960-9822},
  doi = {https://doi.org/10.1016/j.cub.2014.04.039},
  url = {https://www.sciencedirect.com/science/article/pii/S0960982214004771},
  author = {David {van Dijk} and Ohad Manor and Lucas B. Carey}
}

@inproceedings{mitra2014,
  author = {Mitra, Tanushree and Gilbert, Eric},
  year = {2014},
  month = {02},
  pages = {49-61},
  title = {The language that gets people to give: Phrases that predict success on kickstarter},
  journal = {Proceedings of the ACM Conference on Computer Supported Cooperative Work, CSCW},
  doi = {10.1145/2531602.2531656}
}

@techreport{paolo2014,
  address = {Jena},
  author = {Paolo Crosetto and Tobias Regner},
  copyright = {http://www.econstor.eu/dspace/Nutzungsbedingungen},
  keywords = {D0; G32; ; 330; crowdfunding; donations; entrepreneurial finance; pre-selling},
  language = {eng},
  number = {2014-035},
  publisher = {Friedrich Schiller University Jena and Max Planck Institute of Economics},
  title = {Crowdfunding: Determinants of success and funding dynamics},
  type = {Jena Economic Research Papers},
  url = {http://hdl.handle.net/10419/108542},
  year = {2014}
}

@inproceedings{greenberg2013,
  author = {Greenberg, Michael and Pardo, Bryan and Hariharan, Karthic and Gerber, Elizabeth},
  year = {2013},
  month = {04},
  pages = {1815-1820},
  title = {Crowdfunding support tools: Predicting success \& failure},
  doi = {10.1145/2468356.2468682}
}

@article{jordan1999,
  author = {Jordan, Michael and Ghahramani, Zoubin and Jaakkola, Tommi and Saul, Lawrence},
  year = {1999},
  month = {01},
  pages = {183-233},
  title = {An Introduction to Variational Methods for Graphical Models},
  volume = {37},
  isbn = {978-94-010-6104-9},
  journal = {Machine Learning},
  doi = {10.1023/A:1007665907178}
}

@article {Alberts787,
	author = {Alberts, Bruce},
	title = {Impact Factor Distortions},
	volume = {340},
	number = {6134},
	pages = {787--787},
	year = {2013},
	doi = {10.1126/science.1240319},
	publisher = {American Association for the Advancement of Science},
	issn = {0036-8075},
	URL = {https://science.sciencemag.org/content/340/6134/787},
	eprint = {https://science.sciencemag.org/content/340/6134/787.full.pdf},
	journal = {Science}
}

@Manual{UKRI,
title = {UK Research and Innovation GtR Database},
year = {2021},
publisher = {UK Research and Innovation},
howpublished = {\url{https://gtr.ukri.org/search/project?term=*}},
note = {[Accessed: August 20, 2021]}
}

@Manual{NSF,
title = {National Science Foundation Funded Project Database},
year = {2021},
publisher = {National Science Foundation},
howpublished = {\url{https://www.nsf.gov/awardsearch/download.jsp}},
note = {[Accessed: August 20, 2021]}
}

@Manual{NIH,
title = {National Institutes of Health RePORTER Database},
year = {2021},
publisher = {National Institutes of Health},
howpublished = {\url{https://reporter.nih.gov/search/JbRgAtchAUKHOoW2X1vObQ/projects}},
note = {[Accessed: August 20, 2021]}
}

@Manual{ERC,
title = {European Research Council Funded Project Database},
year = {2021},
publisher = {European Research Council},
howpublished = {\url{https://erc.europa.eu/projects-figures/project-database}},
note = {[Accessed: August 20, 2021]}
}

@Manual{scipy,
title = {Hungarian algorithm to solve the linear sum assignment problem},
year = {2021},
publisher = {Scipy.org},
howpublished = {\url{https://docs.scipy.org/doc/scipy/reference/tutorial/optimize.html#assignment-problems}},
note = {Version 1.7.1}
}

@Manual{sklearn,
title = {scikit-learn: Machine Learning in Python.},
year = {2007},
publisher = {scikit-learn.org},
howpublished = {\url{https://scikit-learn.org/stable/about.html}},
note = {Version 0.24.2}
}

@Manual{fixer,
title = {Foreign exchange rates and currency conversion JSON API},
year = {2021},
publisher = {Fixer API},
howpublished = {\url{https://fixer.io/documentation}},
note = {[Accessed: August 20, 2021]}
}

@Manual{gensim,
title = {Gensim: Topic Modelling for Humans},
year = {2009},
publisher = {Gensim API},
howpublished = {\url{https://radimrehurek.com/gensim/auto_examples/index.html#documentation}},
note = {[Accessed: August 20, 2021]}
}

@misc{taddy2011estimation,
      title={On Estimation and Selection for Topic Models},
      author={Matthew A. Taddy},
      year={2011},
      eprint={1109.4518},
      archivePrefix={arXiv},
      primaryClass={stat.AP}
}

@inproceedings{Ke2017,
author = {Ke, Guolin and Meng, Qi and Finley, Thomas and Wang, Taifeng and Chen, Wei and Ma, Weidong and Ye, Qiwei and Liu, Tie-Yan},
title = {LightGBM: A Highly Efficient Gradient Boosting Decision Tree},
year = {2017},
isbn = {9781510860964},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {Gradient Boosting Decision Tree (GBDT) is a popular machine learning algorithm, and
has quite a few effective implementations such as XGBoost and pGBRT. Although many
engineering optimizations have been adopted in these implementations, the efficiency
and scalability are still unsatisfactory when the feature dimension is high and data
size is large. A major reason is that for each feature, they need to scan all the
data instances to estimate the information gain of all possible split points, which
is very time consuming. To tackle this problem, we propose two novel techniques: Gradient-based
One-Side Sampling (GOSS) and Exclusive Feature Bundling (EFB). With GOSS, we exclude
a significant proportion of data instances with small gradients, and only use the
rest to estimate the information gain. We prove that, since the data instances with
larger gradients play a more important role in the computation of information gain,
GOSS can obtain quite accurate estimation of the information gain with a much smaller
data size. With EFB, we bundle mutually exclusive features (i.e., they rarely take
nonzero values simultaneously), to reduce the number of features. We prove that finding
the optimal bundling of exclusive features is NP-hard, but a greedy algorithm can
achieve quite good approximation ratio (and thus can effectively reduce the number
of features without hurting the accuracy of split point determination by much). We
call our new GBDT implementation with GOSS and EFB LightGBM. Our experiments on multiple
public datasets show that, LightGBM speeds up the training process of conventional
GBDT by up to over 20 times while achieving almost the same accuracy.},
booktitle = {Proceedings of the 31st International Conference on Neural Information Processing Systems},
pages = {3149–3157},
numpages = {9},
location = {Long Beach, California, USA},
series = {NIPS'17}
}

@article{jerome2001,
author = {Jerome H. Friedman},
title = {{Greedy function approximation: A gradient boosting machine.}},
volume = {29},
journal = {The Annals of Statistics},
number = {5},
publisher = {Institute of Mathematical Statistics},
pages = {1189 -- 1232},
keywords = {boosting, decision trees, Function estimation, robust nonparametric regression},
year = {2001},
doi = {10.1214/aos/1013203451},
URL = {https://doi.org/10.1214/aos/1013203451}
}

@inproceedings{li2010,
author = {Li, Ping},
title = {Robust Logitboost and Adaptive Base Class (ABC) Logitboost},
year = {2010},
isbn = {9780974903965},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {Logitboost is an influential boosting algorithm for classification. In this paper,
we develop robust logitboost to provide an explicit formulation of tree-split criterion
for building weak learners (regression trees) for logitboost. This formulation leads
to a numerically stable implementation of logitboost. We then propose abc-logitboost
for multi-class classification, by combining robust logitboost with the prior work
of abc-boost. Previously, abc-boost was implemented as abc-mart using the mart algorithm.Our
extensive experiments on multi-class classification compare four algorithms: mart,
abc-mart, (robust) logitboost, and abc-logitboost, and demonstrate the superiority
of abc-logitboost. Comparisons with other learning methods including SVM and deep
learning are also available through prior publications.},
booktitle = {Proceedings of the Twenty-Sixth Conference on Uncertainty in Artificial Intelligence},
pages = {302–311},
numpages = {10},
location = {Catalina Island, CA},
series = {UAI'10}
}

@techreport{burges2010,
author = {Burges, Chris J.C.},
title = {From RankNet to LambdaRank to LambdaMART: An Overview},
year = {2010},
month = {June},
abstract = {LambdaMART is the boosted tree version of LambdaRank, which is based on RankNet. RankNet, LambdaRank, and LambdaMART have proven to be very successful algorithms for solving real world ranking problems: for example an ensemble of LambdaMART rankers won Track 1 of the 2010 Yahoo! Learning To Rank Challenge. The details of these algorithms are spread across several papers and reports, and so here we give a self-contained, detailed and complete description of them.},
url = {https://www.microsoft.com/en-us/research/publication/from-ranknet-to-lambdarank-to-lambdamart-an-overview/},
number = {MSR-TR-2010-82},
}

@inproceedings{aletras2013,
author = {Aletras, Nikolaos and Stevenson, Mark},
year = {2013},
month = {03},
pages = {13-22},
title = {Evaluating Topic Coherence Using Distributional Semantics}
}

@inproceedings{newman2010,
author = {Newman, David and Lau, Jey Han and Grieser, Karl and Baldwin, Timothy},
title = {Automatic Evaluation of Topic Coherence},
year = {2010},
isbn = {1932432655},
publisher = {Association for Computational Linguistics},
address = {USA},
abstract = {This paper introduces the novel task of topic coherence evaluation, whereby a set
of words, as generated by a topic model, is rated for coherence or interpretability.
We apply a range of topic scoring models to the evaluation task, drawing on WordNet,
Wikipedia and the Google search engine, and existing research on lexical similarity/relatedness.
In comparison with human scores for a set of learned topics over two distinct datasets,
we show a simple co-occurrence measure based on pointwise mutual information over
Wikipedia data is able to achieve results for the task at or nearing the level of
inter-annotator correlation, and that other Wikipedia-based lexical relatedness methods
also achieve strong results. Google produces strong, if less consistent, results,
while our results over WordNet are patchy at best.},
booktitle = {Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics},
pages = {100–108},
numpages = {9},
location = {Los Angeles, California},
series = {HLT '10}
}

@inproceedings{lau2014,
    title = "Machine Reading Tea Leaves: Automatically Evaluating Topic Coherence and Topic Model Quality",
    author = "Lau, Jey Han  and
      Newman, David  and
      Baldwin, Timothy",
    booktitle = "Proceedings of the 14th Conference of the {E}uropean Chapter of the Association for Computational Linguistics",
    month = apr,
    year = "2014",
    address = "Gothenburg, Sweden",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/E14-1056",
    doi = "10.3115/v1/E14-1056",
    pages = "530--539"
}

@inproceedings{Mimno2011,
author = {Mimno, David and Wallach, Hanna M. and Talley, Edmund and Leenders, Miriam and McCallum, Andrew},
title = {Optimizing Semantic Coherence in Topic Models},
year = {2011},
isbn = {9781937284114},
publisher = {Association for Computational Linguistics},
address = {USA},
abstract = {Latent variable models have the potential to add value to large document collections
by discovering interpretable, low-dimensional subspaces. In order for people to use
such models, however, they must trust them. Unfortunately, typical dimensionality
reduction methods for text, such as latent Dirichlet allocation, often produce low-dimensional
subspaces (topics) that are obviously flawed to human domain experts. The contributions
of this paper are threefold: (1) An analysis of the ways in which topics can be flawed;
(2) an automated evaluation metric for identifying such topics that does not rely
on human annotators or reference collections outside the training data; (3) a novel
statistical topic model based on this metric that significantly improves topic quality
in a large-scale document collection from the National Institutes of Health (NIH).},
booktitle = {Proceedings of the Conference on Empirical Methods in Natural Language Processing},
pages = {262–272},
numpages = {11},
location = {Edinburgh, United Kingdom},
series = {EMNLP '11}
}

@inproceedings{bouma2009,
  title={Normalized (pointwise) mutual information in collocation extraction},
  author={G. Bouma},
  year={2009}
}

@article{fitelson2003,
 ISSN = {00032638, 14678284},
 URL = {http://www.jstor.org/stable/3329309},
 author = {Branden Fitelson},
 journal = {Analysis},
 number = {3},
 pages = {194--199},
 publisher = {[Analysis Committee, Oxford University Press]},
 title = {A Probabilistic Theory of Coherence},
 volume = {63},
 year = {2003}
}

@inproceedings{Kannan2016StockMP,
  title={Stock Market Prediction and Analysis Using Naïve Bayes},
  author={K. Kannan and P. Sekar and M. Sathik and Adel Assaf},
  year={2016}
}

@inproceedings{mariana2017,
  title={The Cultural Evolution of Evolution},
  author={Marina Papadopoulou},
  year={2017}
}

@article{hilbert2016,
author = {Hilbert, Martin},
title = {Big Data for Development: A Review of Promises and Challenges},
journal = {Development Policy Review},
volume = {34},
number = {1},
pages = {135-174},
keywords = {Big Data, decision-making, innovation, Information and Communication Technology (ICT), digital divide, digital, international development},
doi = {https://doi.org/10.1111/dpr.12142},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/dpr.12142},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1111/dpr.12142},
abstract = {The article uses a conceptual framework to review empirical evidence and some 180 articles related to the opportunities and threats of Big Data Analytics for international development. The advent of Big Data delivers a cost-effective prospect for improved decision-making in critical development areas such as healthcare, economic productivity and security. At the same time, the well-known caveats of the Big Data debate, such as privacy concerns and human resource scarcity, are aggravated in developing countries by long-standing structural shortages in the areas of infrastructure, economic resources and institutions. The result is a new kind of digital divide: a divide in the use of data-based knowledge to inform intelligent decision-making. The article systematically reviews several available policy options in terms of fostering opportunities and minimising risks.},
year = {2016}
}

@article{ahmed2009,
author = {Ahmed, Farag and Nürnberger, Andreas},
title = {Evaluation of n-gram conflation approaches for Arabic text retrieval},
journal = {Journal of the American Society for Information Science and Technology},
volume = {60},
number = {7},
pages = {1448-1465},
doi = {https://doi.org/10.1002/asi.21063},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/asi.21063},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/asi.21063},
abstract = {Abstract In this paper we present a language-independent approach for conflation that does not depend on predefined rules or prior knowledge of the target language. The proposed unsupervised method is based on an enhancement of the pure n-gram model that can group related words based on various string-similarity measures, while restricting the search to specific locations of the target word by taking into account the order of n-grams. We show that the method is effective to achieve high score similarities for all word-form variations and reduces the ambiguity, i.e., obtains a higher precision and recall, compared to pure n-gram-based approaches for English, Portuguese, and Arabic. The proposed method is especially suited for conflation approaches in Arabic, since Arabic is a highly inflectional language. Therefore, we present in addition an adaptive user interface for Arabic text retrieval called “araSearch”. araSearch serves as a metasearch interface to existing search engines. The system is able to extend a query using the proposed conflation approach such that additional results for relevant subwords can be found automatically.},
year = {2009}
}

@article{wang2020,
author = {Wang, Yan and Wang, Tao},
year = {2020},
month = {05},
pages = {3227},
title = {Application of Improved LightGBM Model in Blood Glucose Prediction},
volume = {10},
journal = {Applied Sciences},
doi = {10.3390/app10093227}
}
