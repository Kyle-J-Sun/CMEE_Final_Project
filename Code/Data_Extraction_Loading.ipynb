{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5b1d9af-bbe5-421b-98da-0fe75606e9ea",
   "metadata": {},
   "source": [
    "# DATA Scraping and Extraction for four agencies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702a143e-0393-4182-9947-37fc90ef9483",
   "metadata": {},
   "source": [
    "# Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57762dbd-d82b-44c5-ab01-d6f7eb1853e3",
   "metadata": {},
   "source": [
    "## NIH DATASET COLLECTION\n",
    "\n",
    "Beacuse I can only extract data of information of 15000 projects for a single time, I extracted all projects for 6 times."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ecb429-b500-44f7-ba20-2ab5ce1ef2db",
   "metadata": {},
   "source": [
    "### (1) Import NIH datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ca6ff2b-ead0-4117-8f17-6781e3a6dbe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import NIH datasets\n",
    "# NIH1 = pd.read_csv(\"../Data/NIH/NIHFundedData1.csv\")\n",
    "# NIH2 = pd.read_csv(\"../Data/NIH/NIHFundedData2.csv\")\n",
    "# NIH3 = pd.read_csv(\"../Data/NIH/NIHFundedData3.csv\")\n",
    "# NIH4 = pd.read_csv(\"../Data/NIH/NIHFundedData4.csv\")\n",
    "# NIH5 = pd.read_csv(\"../Data/NIH/NIHFundedData5.csv\")\n",
    "# NIH6 = pd.read_csv(\"../Data/NIH/NIHFundedData6.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82dcb069-bde6-4b36-9867-aecf4e7f599f",
   "metadata": {},
   "source": [
    "### (2) Concatenate all datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d882467c-91e8-4d05-89e6-e9f72d2f2f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# frames = [NIH1, NIH2, NIH3, NIH4, NIH5, NIH6]\n",
    "# df = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9c79c2-a3a8-437f-8599-9ee8678884b8",
   "metadata": {},
   "source": [
    "### (3) Save dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a6ac393-4901-44ed-939e-518b5998ce83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# f.columns = df.columns.map(lambda x: x.replace(\" \", \"\"))\n",
    "# df.to_csv(\"../Data/NIHFundedData.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521dc480-f01e-48d1-823a-bbf2758ceab5",
   "metadata": {},
   "source": [
    "## NSF DATASET COLLECTION\n",
    "\n",
    "I first downloaded all xml files, where each file contain information of one project. So I first obtained all xml filenames and iterated them to extract info of each project. Then the final dataset will be saved into local directory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e445c5-6336-46b1-913a-c39f71cdf0ad",
   "metadata": {},
   "source": [
    "### (1) Extract NSF info from all xml-format files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f7e82792-568a-4f2f-8fdb-259e2a19138f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNSFDataset(amt = None, path = \"/Users/kyle/Documents/IC/ALL_Courses/Final_Projects/Data/NSF/\", verbose = False):\n",
    "    \"\"\" Parse XML file to get all NSF funded data \"\"\"\n",
    "    ## Getting all xml filenames we have\n",
    "    subdirnames = []\n",
    "    filenames = []\n",
    "    for (dir, subdir, files) in os.walk(path):\n",
    "        for names in subdir:\n",
    "            subdirnames.append(names)\n",
    "        for name in files:\n",
    "            if name.split(\".\")[1] == \"xml\":\n",
    "                filenames.append(os.path.join(dir, name))\n",
    "                \n",
    "    amt = len(filenames) if amt == None else amt\n",
    "    \n",
    "    ## Processing xml files\n",
    "    for fileNum in tqdm(range(amt)):\n",
    "        if verbose:\n",
    "            print(\"Processing number {}, file {}\".format(fileNum, filenames[fileNum].split(\"/\")[10]))\n",
    "        try:\n",
    "            tree = et.parse(filenames[fileNum])\n",
    "            root = tree.getroot()\n",
    "        except Exception as msg:\n",
    "            if re.match('no element found', str(msg)):\n",
    "                print(\"Loading file {} failed\".format(filenames[fileNum].split(\"/\")[10]))\n",
    "                pass\n",
    "            else:\n",
    "                raise ValueError(\"Parse failed in file number {}, the file path is {}\".format(fileNum, filenames[fileNum]))\n",
    "\n",
    "        ## to iterate the xml formatted 'tree'\n",
    "        dic = {}\n",
    "        for elem in root:\n",
    "            for subelem in elem:\n",
    "                if subelem.text == '\\n':\n",
    "                    for subelem2 in subelem:\n",
    "                        if subelem2.text == '\\n':\n",
    "                            for subelem3 in subelem2:\n",
    "                                name = \"{}_{}\".format(subelem3.tag, subelem2.tag)\n",
    "                                dic[name] = [subelem3.text]\n",
    "                        else:\n",
    "                            name = \"{}_{}\".format(subelem2.tag, subelem.tag)\n",
    "                            dic[name] = [subelem2.text]\n",
    "                else:\n",
    "                    dic[subelem.tag] = [subelem.text]\n",
    "        dic[\"FiscalYear\"] = filenames[fileNum].split(\"/\")[9]\n",
    "        if 'DRECONTENT_POR' in dic:\n",
    "            del dic['DRECONTENT_POR'] \n",
    "        \n",
    "        ## Removing punctuations for AwardTitle, AbstractNarration and POR_COPY_TXT_POR columns\n",
    "        dic['AwardTitle'] = [remove_punctuation(dic['AwardTitle'][0])] if dic['AwardTitle'][0] != None else dic['AwardTitle']\n",
    "        dic['AbstractNarration'] = [remove_punctuation(dic['AbstractNarration'][0])] if dic['AbstractNarration'][0] != None else dic['AbstractNarration']\n",
    "        if 'POR_COPY_TXT_POR' in dic:\n",
    "            dic['POR_COPY_TXT_POR'] = [remove_punctuation(dic['POR_COPY_TXT_POR'][0])] \n",
    "\n",
    "        if fileNum == 0:\n",
    "            df = pd.DataFrame(dic)\n",
    "        else:\n",
    "            df = df.append(dic, ignore_index=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ac03081-b306-473a-9cfb-a6f6a3ce9b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# df = getNSFDataset(path = \"/Users/kyle/Documents/IC/ALL_Courses/Final_Projects/Data/NSF/\", verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33eab565-2816-4cef-8c1d-dd97e27709a7",
   "metadata": {},
   "source": [
    "### (2) A Little Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c8d5c3a3-fd29-41c8-8c18-e31f25756b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_list(x):\n",
    "    \"\"\" Romving list of each elemnt within dataframe \"\"\"\n",
    "    for idx in range(len(x)):\n",
    "        if type(x[idx]) == list:\n",
    "            x[idx] = x[idx][0]\n",
    "        else:\n",
    "            x[idx] = x[idx]\n",
    "    return \"Finished!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c92a3b2f-c060-4b87-bedd-2359a09b076b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# df.apply(remove_list, axis = 1)\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9b7adea2-a78b-4637-a9c7-5297f3dc64b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df[[\"AwardTitle\", \"FiscalYear\", \"AGENCY\", \"AwardEffectiveDate\", \"AwardExpirationDate\", \n",
    "#     \"AwardTotalIntnAmount\", \"AwardAmount\", \"AbstractNarration\", \"MinAmdLetterDate\", \"MaxAmdLetterDate\",\n",
    "#     \"TRAN_TYPE\", \"CFDA_NUM\", \"NSF_PAR_USE_FLAG\", \"FUND_AGCY_CODE\", \"AWDG_AGCY_CODE\", \"AwardID\", \"FUND_OBLG\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da52cba9-51c0-4af3-8c61-b0c9ec5a5831",
   "metadata": {},
   "source": [
    "### (3) Save dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "912df4a0-4da4-48e6-9382-50677e55d784",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv(\"../Data/NSF_Funded_Data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b5b392-0fee-4710-a3e6-cfaddb9b4031",
   "metadata": {},
   "source": [
    "## UKRI ABSTRACT COLLECTION\n",
    "\n",
    "I first downloaded information of all projects without abstract data. Then I used GtR api to extract all abstarct data for each project."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb67383-6b17-4fc2-b530-e63857136aa3",
   "metadata": {},
   "source": [
    "### (1) Create a class for accessing MySQL database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b9dd9574-65b3-4703-80b6-e9add002f4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MySQLPipline(object):\n",
    "    \"\"\" Define Class for MySQL Connection\"\"\"\n",
    "    def __init__(self, database = 'funding'):\n",
    "        \"\"\" Initialize object \"\"\"\n",
    "        self.conn = pymysql.connect(\n",
    "            host = 'localhost', port = 3306, user = 'root', passwd = 'Kyle9975', db = self.database, charset = 'utf8')\n",
    "        self.conn.autocommit(True)\n",
    "        self.cursor = self.conn.cursor()\n",
    "\n",
    "    def process_Query(self, sql, colnames):\n",
    "        \"\"\" Processing the SQL query\"\"\"\n",
    "        self.cursor.execute(sql)\n",
    "        data = self.cursor.fetchall()\n",
    "        data = pd.DataFrame(data)\n",
    "        data.columns = colnames\n",
    "        return data\n",
    "    \n",
    "    def INSERT_Query_UKRI(self, item):\n",
    "        sql = 'INSERT INTO UKRI_Funded_ALL_Raw (TITLE, ProRef, OrgName, sDate, eDate, institution, department, projType, PIFirstName, PISurname, Amount, url, Abstract, resSub, resTopic) values (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s);'\n",
    "        iteminfo = [item['title'][0], item['proRef'][0], item['orgName'][0], item['sDate'][0], item['eDate'][0], item['institution'][0], item['department'][0], item['projType'][0], item[\"PIFirstName\"][0], item[\"PISurname\"][0], item[\"Amount\"][0], item[\"url\"][0], item[\"abstract\"], str(item[\"resSub\"]), str(item['resTopic'])]\n",
    "        self.cursor.execute(sql, iteminfo)\n",
    "        return item\n",
    "    \n",
    "    def INSERT_Query_ERC(self, itemInfo):\n",
    "        sql = 'INSERT INTO ERC_NEW (project_number, title, abstract, grant_type, topic, amount, project_ID, sDate, eDate, institution) values (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s);'\n",
    "        iteminfo = itemInfo\n",
    "        self.cursor.execute(sql, iteminfo)\n",
    "        return itemInfo\n",
    "\n",
    "    def close_Conn(self):\n",
    "        \"\"\" Closing Connection \"\"\"\n",
    "        self.cursor.close()\n",
    "        self.conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fbfc3d9-457c-4bc7-8865-88b61a6bb43c",
   "metadata": {},
   "source": [
    "### (2) Scraping project abstracts using GtR API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83bc8fe3-c308-4325-b5f9-b5e481a41117",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAbstract(row):\n",
    "    \"\"\" Get abstract for each funded project and directly save them into MySQL database \"\"\"\n",
    "    dic = row.to_dict('list')\n",
    "    ref = dic[\"proRef\"][0]\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            response = requests.get(\"https://gtr.ukri.org/projects?ref={}\".format(ref),\n",
    "            headers = {\n",
    "                'user-agent' : 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_2) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/71.0.3578.98 Safari/537.36'\n",
    "            })\n",
    "            break\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    absPattern = re.compile(\"<gtr:abstractText>(.*?)</gtr:abstractText>\", re.S)\n",
    "    resAbs = re.findall(absPattern, response.text)\n",
    "#     print(resAbs)\n",
    "    dic[\"abstract\"] = resAbs[0] if len(resAbs) != 0 else None\n",
    "    \n",
    "    subPattern = re.compile(\"<gtr:researchSubject>.*?<gtr:text>(.*?)</gtr:text>.*?</gtr:researchSubject>\", re.S)\n",
    "    resSub = re.findall(subPattern, response.text)\n",
    "    dic[\"resSub\"] = resSub if len(resSub) != 0 else None\n",
    "    \n",
    "    topicPattern = re.compile(\"<gtr:researchTopic>.*?<gtr:text>(.*?)</gtr:text>.*?</gtr:researchTopic>\", re.S)\n",
    "    resTopic = re.findall(topicPattern, response.text)\n",
    "    \n",
    "    if len(resTopic) == 0:\n",
    "        resTopic = None\n",
    "    else:\n",
    "        if resTopic[0] == \"Unclassified\":\n",
    "            resTopic = resTopic[0]\n",
    "            \n",
    "    \n",
    "    dic[\"resTopic\"] = resTopic\n",
    "    \n",
    "    UKRI = MySQLPipline()\n",
    "    UKRI.INSERT_Query_UKRI(dic)\n",
    "    UKRI.close_Conn()\n",
    "    \n",
    "    return dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ddde05ca-6fbe-4cc3-834f-870505f057a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in tqdm(range(UKRIdata.shape[0])):\n",
    "#     getAbstract(UKRIdata[UKRIdata.index == i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9fd811d-12ec-4fcb-ae4a-d4545830ff95",
   "metadata": {},
   "source": [
    "## ERC DATA COLLECTION\n",
    "\n",
    "I first downloaded part of infomation of all projects, then I scraped other info that is not exist in my downloaded file from websites and directly save them into MySQL database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0cb0ddc4-8a56-4b6e-a735-1ddfb90868ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get all project IDs\n",
    "# count = 0\n",
    "# projectID = []\n",
    "# all_projects = []\n",
    "# for i in [1,2,3,4,5]:\n",
    "#     response = requests.get(\"https://erc.easme-web.eu/json/list-{}.json\".format(i),\n",
    "#     headers = {\n",
    "#         'user-agent' : 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_2) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/71.0.3578.98 Safari/537.36'\n",
    "#     })\n",
    "#     list_ = response.json()\n",
    "#     for elem in list_['items']:\n",
    "#         for project in elem[\"projects\"]:\n",
    "#             all_projects.append(project)\n",
    "#             projectID.append(project['number'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "01b818b9-460c-44d8-8d95-9893f66cc77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_ERC_data(projectID, allproject):\n",
    "    \"\"\" Scraping project info. like start and end date, project ID and funding amount etc.\"\"\"\n",
    "    title = []\n",
    "    abstract = []\n",
    "    grant_type = []\n",
    "    topic = []\n",
    "    EU_contribution = []\n",
    "    Project_IDs = []\n",
    "    sDate = []\n",
    "    eDate = []\n",
    "    institutions = []\n",
    "\n",
    "    for idx, id_ in enumerate(tqdm(projectID)):\n",
    "#         print(\"request id {}...\".format(id_))\n",
    "        sleep(0.5)\n",
    "    \n",
    "        while True:\n",
    "            try:\n",
    "                response = requests.get(\"https://erc.easme-web.eu/json/projects/project-{}.json\".format(id_),\n",
    "                        headers = {\n",
    "                            'user-agent' : 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_2) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/71.0.3578.98 Safari/537.36'\n",
    "                        })\n",
    "                break\n",
    "            except:\n",
    "                print(\"connection time out! reconnecting...\")\n",
    "                pass\n",
    "\n",
    "        regex = \"\"\".*?<div><label>Project Title:</label> <span>(.*?)</span></div>\"\"\" + \\\n",
    "                \"\"\".*?<p>(.*?)</p>\"\"\" + \\\n",
    "                \"\"\".*?<div><label>Grant Type:</label> <span>(.*?)</span></div>\"\"\" + \\\n",
    "                \"\"\".*?<div><label>Topic:</label> <span>(.*?)</span></div>\"\"\" + \\\n",
    "                \"\"\".*?<div><label>EU Contribution:</label> <span>(.*?)â‚¬</span></div>\"\"\" + \\\n",
    "                \"\"\".*?<div><label>Call ID:</label> <span>(.*?)</span></div>\"\"\" + \\\n",
    "                \"\"\".*?<div><label>Start date:</label> <span>(.*?)</span></div>\"\"\" + \\\n",
    "                \"\"\".*?<div><label>End date:</label> <span>(.*?)</span></div>\"\"\"\n",
    "\n",
    "        regex_host_institutions = '''.*?title=\"(.*?)\">'''\n",
    "        \n",
    "        projectInfo_dic = allproject[idx]\n",
    "\n",
    "        pattern = re.compile(regex, re.S)\n",
    "        pattern_host_institutions = re.compile(regex_host_institutions)\n",
    "        res = re.findall(pattern, response.text)\n",
    "        host_institutions = [ elem.strip() for elem in re.findall(pattern_host_institutions, response.text) ]\n",
    "        \n",
    "        itemInfo = [\n",
    "            projectInfo_dic['number'],\n",
    "            res[0][0],\n",
    "            res[0][1],\n",
    "            res[0][2],\n",
    "            projectInfo_dic['topic'],\n",
    "            projectInfo_dic['budget'],\n",
    "            res[0][5],\n",
    "            res[0][6],\n",
    "            res[0][7],\n",
    "            str(host_institutions)\n",
    "        ]\n",
    "        \n",
    "#         print(itemInfo[0])\n",
    "        \n",
    "        UKRI = MySQLPipline()\n",
    "        UKRI.INSERT_Query_ERC(itemInfo)\n",
    "        UKRI.close_Conn()\n",
    "        \n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "05f90a4b-52b1-4682-a1a3-725bf5021315",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrape_ERC_data(projectID, all_projects)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
